



# ğŸ¤– AI-Powered RAG Chatbot (AI-Assisted Non-Developer Built, Local & Full-Stack) + Agent & MCP Features Under Development (Not Yet Implemented)
# ğŸ¤– AI ê¸°ë°˜ RAG ì±—ë´‡ (AI í™œìš© ë¹„ê°œë°œì ì œì‘, ë¡œì»¬ êµ¬ë™ & í’€ìŠ¤íƒ) + ì—ì´ì „íŠ¸ & MCP ê¸°ëŠ¥ ê°œë°œ ì¤‘

This project implements a comprehensive AI chatbot solution with **Retrieval Augmented Generation (RAG)** capabilities, designed to run entirely in a local environment. Built from the ground up by a non-developer leveraging the power of AI tools, this system integrates a robust Python backend with a user-friendly React/Vite frontend to provide accurate and context-aware responses.

ì´ í”„ë¡œì íŠ¸ëŠ” **ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG)** ê¸°ëŠ¥ì„ ê°–ì¶˜ í¬ê´„ì ì¸ AI ì±—ë´‡ ì†”ë£¨ì…˜ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ì „ì²´ë¥¼ ë¡œì»¬ í™˜ê²½ì—ì„œ êµ¬ë™í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì½”ë”© ê²½í—˜ì´ ì—†ëŠ” ë¹„ê°œë°œìê°€ AI ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì²˜ìŒë¶€í„° êµ¬ì¶•í–ˆìœ¼ë©°, ê°•ë ¥í•œ íŒŒì´ì¬ ë°±ì—”ë“œì™€ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë¦¬ì•¡íŠ¸/ë°”ì´íŠ¸ í”„ë¡ íŠ¸ì—”ë“œë¥¼ í†µí•©í•˜ì—¬ ì •í™•í•˜ê³  ë¬¸ë§¥ì„ ì¸ì§€í•˜ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

## âœ¨ Key Features / ì£¼ìš” ê¸°ëŠ¥

* **Local LLM Integration / ë¡œì»¬ LLM í†µí•©:** Designed for local AI model inference, ensuring data privacy and reducing reliance on cloud services. (ë°ì´í„° í”„ë¼ì´ë²„ì‹œë¥¼ ë³´ì¥í•˜ê³  í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì˜ì¡´ë„ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ë¡œì»¬ AI ëª¨ë¸ ì¶”ë¡ ì— ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤.)
* **Retrieval Augmented Generation (RAG) / ê²€ìƒ‰ ì¦ê°• ìƒì„± (RAG):** Enhances chatbot accuracy by retrieving relevant information from a custom knowledge base (ChromaDB) before generating responses. (ë§ì¶¤í˜• ì§€ì‹ ë°ì´í„°ë² ì´ìŠ¤(ChromaDB)ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•¨ìœ¼ë¡œì¨ ì±—ë´‡ì˜ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.)
* **Full-Stack Architecture / í’€ìŠ¤íƒ ì•„í‚¤í…ì²˜:** Composed of a Python backend (FastAPI) and a React/Vite frontend for a complete, interactive experience. (íŒŒì´ì¬ ë°±ì—”ë“œ(FastAPI)ì™€ ë¦¬ì•¡íŠ¸/ë°”ì´íŠ¸ í”„ë¡ íŠ¸ì—”ë“œë¡œ êµ¬ì„±ëœ í’€ìŠ¤íƒ ì•„í‚¤í…ì²˜ë¡œ ì™„ì „í•˜ê³  ìƒí˜¸ì‘ìš©ì ì¸ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.)
* **Custom Knowledge Base / ë§ì¶¤í˜• ì§€ì‹ ë°ì´í„°ë² ì´ìŠ¤:** Utilizes ChromaDB and SQLite for managing and querying internal knowledge documents. (ë‚´ë¶€ ì§€ì‹ ë¬¸ì„œë¥¼ ê´€ë¦¬í•˜ê³  ì¿¼ë¦¬í•˜ëŠ” ë° ChromaDBì™€ SQLiteë¥¼ í™œìš©í•©ë‹ˆë‹¤.)
* **Modular Design / ëª¨ë“ˆì‹ ì„¤ê³„:** Built with LangChain and LangGraph for flexible and extensible AI workflows. (ìœ ì—°í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ AI ì›Œí¬í”Œë¡œìš°ë¥¼ ìœ„í•´ LangChain ë° LangGraphë¡œ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤.)
* **Non-Developer Empowered Development / ë¹„ê°œë°œìì˜ AI ê¸°ë°˜ ê°œë°œ:** AI ë„êµ¬(Gemini, ChatGPT ë“±)ê°€ ê¸°ì¡´ ì½”ë”© ì§€ì‹ ì—†ì´ë„ ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ ê°œì¸ì—ê²Œ ì–´ë–»ê²Œ í˜ì„ ì‹¤ì–´ì¤„ ìˆ˜ ìˆëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ì¦ê±°ì…ë‹ˆë‹¤.

## ğŸš€ Technologies Used / ì‚¬ìš© ê¸°ìˆ 

### Backend / ë°±ì—”ë“œ
* **Python 3.13**
* **FastAPI:** High-performance web framework for building robust APIs. (ê°•ë ¥í•œ API êµ¬ì¶•ì„ ìœ„í•œ ê³ ì„±ëŠ¥ ì›¹ í”„ë ˆì„ì›Œí¬)
* **LangChain:** Framework for developing applications powered by language models. (ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ í”„ë ˆì„ì›Œí¬)
* **LangGraph:** Building stateful, multi-actor applications with LLMs. (LLMìœ¼ë¡œ ìƒíƒœ ì €ì¥í˜•, ë‹¤ì¤‘ ì•¡í„° ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•)
* **ChromaDB:** Open-source embedding database for RAG. (RAGë¥¼ ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ ì„ë² ë”© ë°ì´í„°ë² ì´ìŠ¤)
* **SQLite:** Lightweight database for managing chat history and basic data. (ì±„íŒ… ê¸°ë¡ ë° ê¸°ë³¸ ë°ì´í„° ê´€ë¦¬ë¥¼ ìœ„í•œ ê²½ëŸ‰ ë°ì´í„°ë² ì´ìŠ¤)
* **(Optional: Ollama/OpenAI API if used for specific model calls / ì„ íƒ ì‚¬í•­: íŠ¹ì • ëª¨ë¸ í˜¸ì¶œì— Ollama/OpenAI API ì‚¬ìš© ì‹œ)**

### Frontend / í”„ë¡ íŠ¸ì—”ë“œ
* **React:** A JavaScript library for building user interfaces. (ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶•ì„ ìœ„í•œ ìë°”ìŠ¤í¬ë¦½íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬)
* **Vite:** Fast build tool for modern web projects. (í˜„ëŒ€ ì›¹ í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ë¹ ë¥¸ ë¹Œë“œ ë„êµ¬)
* **(Optional: Next.js if used in conjunction with React/Vite / ì„ íƒ ì‚¬í•­: React/Viteì™€ í•¨ê»˜ Next.js ì‚¬ìš© ì‹œ)**

## âš™ï¸ How to Run Locally / ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ëŠ” ë°©ë²•

To get this project up and running on your local machine, follow these steps:
(ì´ í”„ë¡œì íŠ¸ë¥¼ ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ë ¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:)

### 1. Clone the Repository / 1. ì €ì¥ì†Œ ë³µì œ

First, open your terminal/command prompt and navigate to the directory where you want to save the project. Then, clone this repository:
(ë¨¼ì € í„°ë¯¸ë„/ëª…ë ¹ í”„ë¡¬í”„íŠ¸ë¥¼ ì—´ê³  í”„ë¡œì íŠ¸ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•œ ë‹¤ìŒ, ì´ ì €ì¥ì†Œë¥¼ ë³µì œí•©ë‹ˆë‹¤:)

```bash
git clone [https://github.com/hushmind3/llmlocalproject05.git](https://github.com/hushmind3/llmlocalproject05.git)
cd llmlocalproject05 # If your project folder is different, adjust accordingly (e.g., cd project05/git)

Note: If your project's root directory is project05/git on your local machine, after cloning, you might need to cd into that specific subdirectory: cd llmlocalproject05/git.
ì°¸ê³ : ë¡œì»¬ ë¨¸ì‹ ì—ì„œ í”„ë¡œì íŠ¸ì˜ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ê°€ project05/gitì¸ ê²½ìš°, ë³µì œ í›„ í•´ë‹¹ í•˜ìœ„ ë””ë ‰í† ë¦¬ë¡œ cd í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: cd llmlocalproject05/git.
2. Backend Setup & Run / 2. ë°±ì—”ë“œ ì„¤ì • ë° ì‹¤í–‰
Navigate into the backend directory, set up the Python virtual environment, install dependencies, and run the server.
(ë°±ì—”ë“œ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ì—¬ íŒŒì´ì¬ ê°€ìƒ í™˜ê²½ì„ ì„¤ì •í•˜ê³ , ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•œ í›„ ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.)

cd backend

# Create and activate a virtual environment
python -m venv venv
# On Windows:
.\venv\Scripts\activate
# On macOS/Linux:
# source venv/bin/activate

# Install Python dependencies
pip install -r requirements.txt

# Run the backend server (using uvicorn as an example)
uvicorn main:app --reload # Adjust 'main:app' if your entry file is different

Note: You might need to set up environment variables (e.g., API keys if using external services) in a .env file within the backend directory. Refer to your backend code for required variables.
ì°¸ê³ : í™˜ê²½ ë³€ìˆ˜(ì˜ˆ: ì™¸ë¶€ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° API í‚¤)ë¥¼ backend ë””ë ‰í† ë¦¬ ë‚´ì˜ .env íŒŒì¼ì— ì„¤ì •í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•„ìš”í•œ ë³€ìˆ˜ëŠ” ë°±ì—”ë“œ ì½”ë“œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
3. Frontend Setup & Run / 3. í”„ë¡ íŠ¸ì—”ë“œ ì„¤ì • ë° ì‹¤í–‰
Open a NEW terminal/command prompt window. Navigate into the frontend directory, install Node.js dependencies, and run the development server.
(ìƒˆ í„°ë¯¸ë„/ëª…ë ¹ í”„ë¡¬í”„íŠ¸ ì°½ì„ ì—½ë‹ˆë‹¤. frontend ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ì—¬ Node.js ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•˜ê³  ê°œë°œ ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.)

cd frontend

# Install Node.js dependencies (assuming npm is used)
npm install # or yarn install if you use yarn (if package.json exists)
# If no package.json, ensure all necessary JS files are linked/served correctly based on your project setup.
# (package.json íŒŒì¼ì´ ì—†ë‹¤ë©´, í”„ë¡œì íŠ¸ ì„¤ì •ì— ë”°ë¼ í•„ìš”í•œ JS íŒŒì¼ë“¤ì´ ì˜¬ë°”ë¥´ê²Œ ì—°ê²°/ì œê³µë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.)

# Run the frontend development server
npm run dev # or yarn dev

4. Access the Chatbot / 4. ì±—ë´‡ ì ‘ì†
Once both the backend and frontend servers are running, open your web browser and navigate to the address where your frontend is serving (usually http://localhost:5173 for Vite, or similar).
(ë°±ì—”ë“œ ë° í”„ë¡ íŠ¸ì—”ë“œ ì„œë²„ê°€ ëª¨ë‘ ì‹¤í–‰ë˜ë©´ ì›¹ ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  í”„ë¡ íŠ¸ì—”ë“œê°€ ì„œë¹„ìŠ¤ë˜ëŠ” ì£¼ì†Œ(ì¼ë°˜ì ìœ¼ë¡œ Viteì˜ ê²½ìš° http://localhost:5173 ë˜ëŠ” ìœ ì‚¬í•œ ì£¼ì†Œ)ë¡œ ì´ë™í•˜ì„¸ìš”.)

ğŸ’¡ Project Vision & Current Status / í”„ë¡œì íŠ¸ ë¹„ì „ ë° í˜„ì¬ ìƒíƒœ
This project aims to demonstrate the potential of local LLMs for personalized and private AI applications.
(ì´ í”„ë¡œì íŠ¸ëŠ” ê°œì¸í™”ë˜ê³  í”„ë¼ì´ë¹—í•œ AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ë¡œì»¬ LLMì˜ ì ì¬ë ¥ì„ ë³´ì—¬ì£¼ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.)

Current Status / í˜„ì¬ ìƒíƒœ:
The implementation involved attempting to integrate agentic workflows using LangGraph. This part of the development is currently paused as I am in the process of finding solutions for specific challenges encountered during the agentic implementation. I am actively seeking solutions and learning more about advanced LangGraph patterns to complete this feature.

(LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ í†µí•©í•˜ë ¤ëŠ” êµ¬í˜„ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. ì´ ê°œë°œ ë¶€ë¶„ì€ í˜„ì¬ ì—ì´ì „íŠ¸ êµ¬í˜„ ì¤‘ ì§ë©´í•œ íŠ¹ì • ë¬¸ì œì— ëŒ€í•œ í•´ê²°ì±…ì„ ì°¾ëŠ” ê³¼ì •ì— ìˆì–´ ì¤‘ë‹¨ëœ ìƒíƒœì…ë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì„ ì™„ì„±í•˜ê¸° ìœ„í•´ ì ê·¹ì ìœ¼ë¡œ í•´ê²°ì±…ì„ ì°¾ê³  ë” ê³ ê¸‰ LangGraph íŒ¨í„´ì„ í•™ìŠµí•˜ê³  ìˆìŠµë‹ˆë‹¤.)

ğŸ™ Acknowledgements / ê°ì‚¬ ë§ì”€
Built with the invaluable assistance of AI (e.g., Gemini, ChatGPT) for guidance, debugging, and code generation. (ê°€ì´ë“œ, ë””ë²„ê¹…, ì½”ë“œ ìƒì„± ë“± AI(ì˜ˆ: Gemini, ChatGPT)ì˜ ê·€ì¤‘í•œ ë„ì›€ìœ¼ë¡œ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤.)
Inspired by the open-source LLM community (LangChain, LangGraph, ChromaDB, Hugging Face). (ì˜¤í”ˆì†ŒìŠ¤ LLM ì»¤ë®¤ë‹ˆí‹°(LangChain, LangGraph, ChromaDB, Hugging Face)ì—ì„œ ì˜ê°ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.)
ğŸ“œ License / ë¼ì´ì„ ìŠ¤
This project is open-source and available under the MIT License (recommended, if you wish to apply one).
(ì´ í”„ë¡œì íŠ¸ëŠ” ì˜¤í”ˆì†ŒìŠ¤ì´ë©° MIT ë¼ì´ì„ ìŠ¤ë¡œ ì œê³µë©ë‹ˆë‹¤ (ì›í•˜ëŠ” ê²½ìš° ì ìš© ê¶Œì¥).)
